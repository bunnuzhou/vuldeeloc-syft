{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd03c685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d08043edc52f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#PART 1: Connect to a Remote Duet Server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msyft\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mduet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"787cffcb85e058f950b708baf52a362c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/duet/__init__.py\u001b[0m in \u001b[0;36mduet\u001b[0;34m(target_id, logging, network_url, loopback, db_path)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         return join_duet(\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mtarget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloopback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloopback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         )\n\u001b[1;32m    163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/duet/__init__.py\u001b[0m in \u001b[0;36mjoin_duet\u001b[0;34m(target_id, network_url, loopback, credential_exchanger)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnetwork_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mnetwork_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_available_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"♫♫♫ > Punching through firewall to OpenGrid Network Node at:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"♫♫♫ > \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/duet/__init__.py\u001b[0m in \u001b[0;36mget_available_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_available_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mnetwork_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mADDR_REPOSITORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork_addr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#PART 1: Connect to a Remote Duet Server\n",
    "import syft as sy\n",
    "duet = sy.duet(\"787cffcb85e058f950b708baf52a362c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e5d2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 2: Setting up a Model and our Data\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,BatchSampler\n",
    "from preprocess_dl_Input_version4 import *\n",
    "#from bgru import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "099db37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"batchSize\":64,\n",
    "          \"vector_dim\":30,#单个样本的单个token的向量维度\n",
    "          \"maxlen\": 900, #单个样本的切片长度\n",
    "          \"dropout\":0.4 , #模型dropout的比例\n",
    "          \"lr\":0.002,\n",
    "          \"no_cuda\":True,\n",
    "          \"seed\":42,\n",
    "          \"log_batchsize\":100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d67ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for remote model\n",
    "remote_torch = duet.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aca006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Masking(sy.Module):\n",
    "    \n",
    "    def __init__(self,torch_ref,mask_value=0., *args):\n",
    "        super(Masking, self).__init__(torch_ref = torch_ref)\n",
    "        self.supports_masking = True\n",
    "        self.mask_value = mask_value\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        a=self.torch_ref.ne(inputs, self.mask_value)\n",
    "        return a.any(dim=-1, keepdim=False, out=None)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        a=self.torch_ref.ne(inputs,self.torch_ref.tensor(self.mask_value))\n",
    "        boolean_mask = a.any(dim=-1, keepdims=True)\n",
    "        return inputs * boolean_mask.type(inputs.dtype)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'mask_value': self.mask_value}\n",
    "        base_config = super(Masking, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    \n",
    "class NonMasking(sy.Module):\n",
    "    \n",
    "    \"\"\"Non Masking Layer\n",
    "    自定义的消除蒙版层，以应对池化不支持蒙版\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, torch_ref,**kwargs):\n",
    "        self.supports_masking = True\n",
    "        super(NonMasking, self).__init__(torch_ref = torch_ref,**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        input_shape = input_shape\n",
    "    \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        #不传输蒙版\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "class BGRU(sy.Module):    \n",
    "    def __init__(self,torch_ref):  \n",
    "        super(BGRU, self).__init__(torch_ref = torch_ref)\n",
    "        #self.masking = Masking(self.torch_ref,[0.0])\n",
    "        self.bgru1 = self.torch_ref.nn.GRU(input_size=30, hidden_size=512, num_layers=1, batch_first=False,bidirectional=True)\n",
    "        self.dropout1 = self.torch_ref.nn.Dropout(p = 0.4, inplace = False)\n",
    "        self.bgru2 = self.torch_ref.nn.GRU(input_size=1024, hidden_size=512, num_layers=1, batch_first=False,bidirectional=True)\n",
    "        self.dropout2 = self.torch_ref.nn.Dropout(p = 0.4, inplace= False)\n",
    "        self.fc =self.torch_ref.nn.Linear(in_features = 1024, out_features = 1, bias = True)\n",
    "        #self.nonmasking = NonMasking(self.torch_ref)\n",
    "        #self.kmax = KMaxPooling(1)\n",
    "        #self.avg = GlobalAveragePooling1D()\n",
    "        self.kmax=self.torch_ref.nn.AdaptiveMaxPool2d((1,1), return_indices=False) \n",
    "        self.avg =self.torch_ref.nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs,vulner_mask_input):\n",
    "        x=inputs.view(64,900,30)\n",
    "        #x = self.masking(x)\n",
    "        x = self.bgru1(x)\n",
    "        x = self.dropout1(x[0])\n",
    "        x = self.bgru2(x)\n",
    "        x = self.dropout2(x[0])\n",
    "        x = self.fc(x)\n",
    "        x = self.torch_ref.sigmoid(x)\n",
    "        sigmoid = x\n",
    "        #x = self.nonmasking(x)\n",
    "        y = vulner_mask_input.view(64,900,900)\n",
    "        x = self.torch_ref.mul(x, y)\n",
    "        x = x.view(64,1, 900*900)\n",
    "        x = self.kmax(x)\n",
    "        x = self.avg(x)\n",
    "        return x,sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16697e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.BGRU object at 0x7efb715d9cd0>\n",
      "<__main__.BGRU object at 0x7efb6b635b90>\n"
     ]
    }
   ],
   "source": [
    "# defining the model \n",
    "# 这里的local_model也可以加载本地经过初始训练后的模型，只有第一次训练才为下面的代码\n",
    "local_model=BGRU(torch)#Creating local model    \n",
    "model = local_model.send(duet) \n",
    "print(local_model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57503c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for cuda \n",
    "has_cuda = False\n",
    "has_cuda_ptr = remote_torch.cuda.is_available()\n",
    "has_cuda = bool(has_cuda_ptr.get(\n",
    "    request_block=True,\n",
    "    reason=\"To run test locally\",\n",
    "    timeout_secs=5,  # change to something slower\n",
    "))\n",
    "use_cuda = not config[\"no_cuda\"] and has_cuda\n",
    "# now we can set the seed\n",
    "remote_torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "device = remote_torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    model.cuda(device)\n",
    "else:\n",
    "    model.cpu()\n",
    "#---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ebd7701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: fe62934d5bd94d699635aae12429b84d&gt;</td>\n",
       "      <td>[dataset_train]</td>\n",
       "      <td></td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: b6250e39bbcf4c4cb7f0fd2f6183bdab&gt;</td>\n",
       "      <td>[labels_train]</td>\n",
       "      <td></td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;UID: 3cb5ed710366470198884395a551ffe7&gt;</td>\n",
       "      <td>[place_sequence_train]</td>\n",
       "      <td></td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;UID: 3ee9b0568e474948879effd4808e81e7&gt;</td>\n",
       "      <td>[train_num]</td>\n",
       "      <td></td>\n",
       "      <td>&lt;class 'syft.lib.python.Int'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID                    Tags  \\\n",
       "0  <UID: fe62934d5bd94d699635aae12429b84d>         [dataset_train]   \n",
       "1  <UID: b6250e39bbcf4c4cb7f0fd2f6183bdab>          [labels_train]   \n",
       "2  <UID: 3cb5ed710366470198884395a551ffe7>  [place_sequence_train]   \n",
       "3  <UID: 3ee9b0568e474948879effd4808e81e7>             [train_num]   \n",
       "\n",
       "  Description                    object_type  \n",
       "0                     <class 'torch.Tensor'>  \n",
       "1                     <class 'torch.Tensor'>  \n",
       "2                     <class 'torch.Tensor'>  \n",
       "3              <class 'syft.lib.python.Int'>  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e320f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(remote_torch,model,weightPath):\n",
    "    if model.is_local:\n",
    "        print(\"Training requires remote model\")\n",
    "        model = model.send(duet)\n",
    "    else:\n",
    "        print(\"remote model\")\n",
    "        model = model  \n",
    "    model.train()\n",
    "    dataset_train = duet.store[\"dataset_train\"]\n",
    "    labels_train = duet.store[\"labels_train\"]\n",
    "    place_sequence_train = duet.store[\"place_sequence_train\"]\n",
    "    train_num = duet.store[\"train_num\"]\n",
    "    iter_num =  train_num.get(request_block=True,reason=\"size of data set\",timeout_secs=5)\n",
    "    \n",
    "    #lab=labels_train.get(\n",
    "     #           reason=\"To evaluate training progress\",\n",
    "      #          request_block=True,\n",
    "       #         timeout_secs=5,\n",
    "        #    )\n",
    "    #print(len(lab))\n",
    "    optimizer = remote_torch.optim.Adam(model.parameters(), config[\"lr\"])\n",
    "    criterion = remote_torch.nn.BCELoss()    \n",
    "    print(\"Train...\")\n",
    "    batch_size = config[\"batchSize\"]\n",
    "    epochs=4\n",
    "    for epoch in range(epochs):\n",
    "        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(\"==========\"*8 + \"%s\"%nowtime)\n",
    "        i=0\n",
    "        j=0\n",
    "        running_loss= sy.lib.python.Float(0.0)\n",
    "        samples=sy.lib.python.Int(0)\n",
    "        for iter in  range(10):\n",
    "            j=j+1\n",
    "            print(batch_size)\n",
    "            for vp in range(batch_size):\n",
    "                #print(place_sequence_train)\n",
    "                vulner_places = remote_torch.diag(place_sequence_train[0*64+vp])\n",
    "                if vp==0:\n",
    "                    batched_vulner_places = vulner_places\n",
    "                    batched_vulner_places=remote_torch.unsqueeze(batched_vulner_places,0)\n",
    "                    batched_vulner_places=batched_vulner_places.expand(64,900,900)\n",
    "                else:\n",
    "                    vulner_places = remote_torch.diag(place_sequence_train[0*64+vp])\n",
    "                    batched_vulner_places[vp]=vulner_places\n",
    "            optimizer.zero_grad()\n",
    "            #iter=0\n",
    "            outputs,_=model(dataset_train[iter],batched_vulner_places)\n",
    "            outputs=outputs.view(batch_size)\n",
    "            #print(\"outpus:\")\n",
    "            #out=outputs.get(\n",
    "             # request_block=True,\n",
    "    #reason=\"To run test locally\",\n",
    "    #timeout_secs=5,  # change to something slower\n",
    "     #       )\n",
    "      #      print(out)\n",
    "            duet.store.pandas\n",
    "            train_num = duet.store[\"labels_train\"]\n",
    "            labels_train[iter]=labels_train[iter].view(batch_size)\n",
    "            #print(\"labels\")\n",
    "           # lab=labels_train[iter].get(\n",
    "            #  request_block=True,\n",
    "    #reason=\"To run test locally\",\n",
    "    #timeout_secs=5,  # change to something slower\n",
    "     #       )\n",
    "      #      print(lab)\n",
    "            #计算loss\n",
    "            loss=criterion(outputs,labels_train[iter])\n",
    "            #print(\"loss\")\n",
    "            #print(loss)\n",
    "            #los=loss.get(\n",
    "             # request_block=True,\n",
    "    #reason=\"To run test locally\",\n",
    "    #timeout_secs=5,  # change to something slower\n",
    "     #       )\n",
    "      #      print(los)\n",
    "                        # 反向传播\n",
    "            loss.backward()\n",
    "            # 计算损失并更新权重\n",
    "            optimizer.step()\n",
    "            running_loss+= remote_torch.mul(loss.item(),labels_train[iter].shape[0])\n",
    "            samples +=labels_train[iter] .shape[0]\n",
    "                        #train_loss = loss_item.resolve_pointer_type()\n",
    "            local_loss = loss.get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5,\n",
    "            )\n",
    "            #print(local_loss)\n",
    "            print('batch [{}/{}], Loss: {:.4f}'.format(j,\"9\", local_loss))\n",
    "            if i%100 == 0:\n",
    "                i = i + batch_size\n",
    "        l = running_loss.get(request_block=True,reason=\"To evaluate training progress\",timeout_secs=5)/samples.get(request_block=True,reason=\"To evaluate training progress\",timeout_secs=5)\n",
    "        print('Epoch [{}], Loss: {:.4f}'.format(epoch + 1, l))\n",
    "        #保存模型\n",
    "    remote_torch.save(model.state_dict(), weightPath)\n",
    "    print(\"训练完成...\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb35027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试相关函数\n",
    "def sample_threshold_windows(value_sequence, linetokens, argv):\n",
    "    \"\"\"read the output of RNN deaplearning model output sequence and return the classify result\n",
    "    \n",
    "    Input the output of RNN model's top activation(sigmoid) layer,\n",
    "    read them by time step, and judge the value according to the threshold\n",
    "    value, count the average that value bigger than threshold, and return the\n",
    "    classify result 1 or 0.\n",
    "    根据模型的顶层输出窗口读取，窗口内平均值超过阈值则认定为有漏洞\n",
    "    \n",
    "    # Arguments\n",
    "        value_sequence: The output sequence from RNN model\n",
    "        linetokens: The index of first token each line      // 句首token索引值\n",
    "        argv: The dict of argument, contain 'k' 'threshold_value'\n",
    "    \n",
    "    # Returns\n",
    "        linenum: The line predict to have vulnerability's line num      // 报为有漏洞的切片行号\n",
    "    \"\"\"\n",
    "        \n",
    "    #检查参数是否有效\n",
    "    if \"threshold_value\" in argv: #argv是参数列表，包括阈值和K值\n",
    "        threshold_value = argv[\"threshold_value\"]\n",
    "    else:\n",
    "        print(\"Error:Bad threshold value!\")\n",
    "        return -1\n",
    "    if \"k\" in argv:\n",
    "        k = argv[\"k\"]\n",
    "    else:\n",
    "        k = 3\n",
    "        \n",
    "    #删除尾部重复数值\n",
    "    value_sequence = list(value_sequence)\n",
    "   # print('value_sequence',len(value_sequence))##############################################\n",
    "    vs = len(value_sequence)-1\n",
    "    while value_sequence[vs] == value_sequence[-1]:\n",
    "        vs -= 1\n",
    "    value_sequence = value_sequence[:vs+2]\n",
    "    #print('value_sequence',len(value_sequence))    ##############################################\n",
    "    #标注序列的终止位置为序列长度\n",
    "    for tokenindex in range(len(linetokens)):\n",
    "        if len(value_sequence) <= linetokens[tokenindex]:\n",
    "            linetokens = linetokens[:tokenindex]\n",
    "            linetokens.append(len(value_sequence))\n",
    "            break\n",
    "    if len(value_sequence) > linetokens[-1]:\n",
    "        linetokens.append(len(value_sequence))\n",
    "   # print('linetokens',len(linetokens))##############################################\n",
    "    #扫描每一行，输出序列窗口内k-max的平均值大于阈值则认定为有漏洞(对每一行取前K个最大值的平均值，平均值大于阈值就是有漏洞，取该漏洞行行号作为输出结果)\n",
    "    linenum = []\n",
    "    for i in range(len(linetokens)-1):\n",
    "        left = linetokens[i]\n",
    "        right = linetokens[i+1]\n",
    "        if left == right:\n",
    "            right += 1\n",
    "        window = value_sequence[left: right]\n",
    "        window = [x[0] for x in window]\n",
    "        window.sort(reverse = True)\n",
    "        k_max = window[:k]\n",
    "        #print(\"sum(k_max)/ len(k_max)\",sum(k_max)/ len(k_max))##################################\n",
    "        if sum(k_max)/ len(k_max) > threshold_value:\n",
    "            #如果该行被认定为有漏洞\n",
    "            linenum.append(i)\n",
    "    \n",
    "    return linenum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a599b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_of_data1(torch_ref,data, labels, linetokens, vpointers, batchsize, maxlen, vector_dim):\n",
    "    #输入数据生成器\n",
    "    iter_num = int(len(data) / batchsize)\n",
    "    i = 0\n",
    "    \n",
    "    while iter_num:\n",
    "        batchdata = data[i:i + batchsize]\n",
    "        batched_input = process_sequences_shape(batchdata, maxLen=maxlen, vector_dim=vector_dim)\n",
    "        batched_labels = labels[i:i + batchsize]\n",
    "        batched_linetokens = linetokens[i:i + batchsize]\n",
    "        batched_vpointers = vpointers[i:i + batchsize]\n",
    "        \n",
    "        #计算漏洞位置的对角矩阵\n",
    "        batched_vulner_places = []\n",
    "        for vp in range(len(batched_vpointers)):\n",
    "            place_sequence = sample_place_sequence(maxlen, batched_vpointers[vp], batched_linetokens[vp])\n",
    "            vulner_places = np.diag(place_sequence)     #得到numpy格式的漏洞位置对角矩阵\n",
    "            batched_vulner_places.append(vulner_places)\n",
    "        batched_vulner_places = np.array(batched_vulner_places)\n",
    "   ###########################################################################     \n",
    "        batched_input=torch_ref.tensor(batched_input,dtype=torch_ref.float32)\n",
    "        batched_labels=torch_ref.tensor(batched_labels,dtype=torch_ref.float32) \n",
    "        batched_vulner_places = torch_ref.tensor(batched_vulner_places,dtype=torch_ref.float32)#zheli  \n",
    "        \n",
    "        yield ([batched_input, batched_vulner_places], batched_labels)\n",
    "        i = i + batchsize\n",
    "        \n",
    "        iter_num -= 1\n",
    "        if iter_num == 0:\n",
    "            iter_num = int(len(data) / batchsize)\n",
    "            i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acbb49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(local_model,torch_ref,batch_size, maxlen, vector_dim,weightPath,testdataSet_path,resultPath):\n",
    "    #测试阶段开始\n",
    "    #加载模型\n",
    " #   print(\"加载模型\")\n",
    "    #model=BGRU(torch)\n",
    "    #model.load_state_dict(torch.load(weightPath))\n",
    "    #local_model.load(weightPath)\n",
    " #   if not model.is_local:\n",
    "#        local_model = model.get(request_block=True,name=\"model_download\",reason=\"test evaluation\",timeout_secs=5)\n",
    "#    else:\n",
    "#        local_model = model\n",
    "#    print(\"加载模型完成\")   \n",
    "    local_model.eval()\n",
    "        \n",
    "    dataset = []\n",
    "    linetokens = []\n",
    "    vpointers = []\n",
    "    funcs = []\n",
    "    testcase = []\n",
    "    print(\"Test...\")\n",
    "    for filename in os.listdir(testdataSet_path):\n",
    "        if(filename.endswith(\".pkl\") is False):\n",
    "            continue\n",
    "        print(filename)\n",
    "        f = open(os.path.join(testdataSet_path,filename),\"rb\")\n",
    "        #分别是样本向量、句子拆分点、漏洞点、goodbad函数表、句子语料、testcase切片名\n",
    "        dataset_file, linetokens_file, vpointers_file, funcs_file, corpus_file, testcase_file = pickle.load(f,encoding = 'iso-8859-1')\n",
    "        f.close()\n",
    "        dataset += dataset_file\n",
    "        linetokens += linetokens_file\n",
    "        vpointers += vpointers_file\n",
    "        funcs += funcs_file\n",
    "        testcase +=testcase_file\n",
    "    print(len(dataset),len(testcase))\n",
    "    \n",
    "        #按照漏洞点和所属函数生成0/1标签\n",
    "    labels = []\n",
    "    for vp in range(len(vpointers)):\n",
    "        if vpointers[vp] != []:\n",
    "            label = 1\n",
    "            for func in funcs[vp]:\n",
    "                if \"good\" in func:\n",
    "                    label = 0\n",
    "                    break\n",
    "        else:\n",
    "            label = 0   #无漏洞的切片的漏洞点标签为空\n",
    "        labels.append(label)\n",
    "        \n",
    "        #测试模型\n",
    "    batch_size = 64\n",
    "    test_generator = generator_of_data1(torch,dataset, labels, linetokens, vpointers, batch_size, maxlen, vector_dim)\n",
    "    all_test_samples = len(dataset)\n",
    "    steps_epoch = int(all_test_samples / batch_size)\n",
    "    #构建测试函数\n",
    " #   get_bgru_output = K.function([model.layers[0].input, K.learning_phase()], [model.layers[7].output]) #一层BGRU时读取第5层，两层BGRU时读取第7层，三层BGRU时读取第9层\n",
    "    #########################################################################################3\n",
    "    \n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    TP_l, TN_l, FP_l, FN_l = 0, 0, 0, 0\n",
    "    TP_index = []\n",
    "    results = {}\n",
    "    dict_testcase2func = {}\n",
    "    start = time.time()\n",
    "    #对于每一个样本做测试\n",
    "    for i in range(steps_epoch):\n",
    "        print(\"\\r\", i, \"/\", steps_epoch, end=\"\")\n",
    "        #测试输入\n",
    "        test_input = next(test_generator)\n",
    "        #深度学习模型的序列输出\n",
    "       # layer_output = get_bgru_output([test_input[0][0],0])\n",
    "        #print(\"test_input[0][0]\",test_input[0][0].shape)\n",
    "        #print(\"test_input[0][1]\",test_input[0][1].shape)\n",
    "        _,layer_output = local_model(test_input[0][0])##############################################,test_input[0][1]\n",
    "        \n",
    "       \n",
    "        ###################################################################################\n",
    "        #测试结果\n",
    "        for j in range(batch_size):\n",
    "            index = i*batch_size + j\n",
    "            #print('\\n',testcase[index])\n",
    "          #  result = sample_threshold_windows(layer_output[0][j], linetokens[index], {'threshold_value':0.5, 'k':1})#result是漏洞行的行号\n",
    "        ##########################################\n",
    "         #   print(\"layer_output\",layer_output.shape)\n",
    "         #   print(\"layer_output[j]\",layer_output[j].shape)\n",
    "            result = sample_threshold_windows(layer_output[j], linetokens[index], {'threshold_value':0.5, 'k':1})\n",
    "            #输出统计\n",
    "            if result:\n",
    "                y_pred = 1\n",
    "            else:\n",
    "                y_pred = 0\n",
    "            #print(\"result\",result,\" y_pred\", y_pred)  ################################           \n",
    "        #漏洞分类的指标 & 漏洞分类的函数级指标 & 保存每个测试样本的序列输出\n",
    "            if y_pred == 0 and labels[index] == 0:\n",
    "                TN += 1\n",
    "                TN_l += 1\n",
    "                with open(\"BGRU/result_analyze_0.4_k1/TN/\"+str(index)+\".pkl\",\"wb\") as f:\n",
    "                    pickle.dump(list([layer_output[0][j]]),f)##############################################\n",
    "                with open(\"BGRU/result_analyze_0.4_k1/TN_testcase_id_0514.txt\",'a+') as ftn:\n",
    "                    ftn.write(testcase[index]+'\\n')\n",
    "            if y_pred == 0 and labels[index] == 1:\n",
    "                FN += 1\n",
    "                FN_l += 1\n",
    "                with open(\"BGRU/result_analyze_0.4_k1/FN/\"+str(index)+\".pkl\",\"wb\") as f:\n",
    "                    pickle.dump(list([layer_output[0][j]]),f)#################################################\n",
    "                with open(\"BGRU/result_analyze_0.4_k1/FN_testcase_id_0514.txt\",'a+') as ffn:\n",
    "                    ffn.write(testcase[index]+'\\n')\n",
    "\t\t\t\t\t\n",
    "            if y_pred == 1 and labels[index] == 0:\n",
    "                FP += 1\n",
    "                FP_l += 1\n",
    "                if not testcase[index].split(\"/\")[0] in dict_testcase2func.keys():\n",
    "                    dict_testcase2func[testcase[index].split(\"/\")[0]]={}\n",
    "                for func in funcs[index]:\n",
    "                    if func in dict_testcase2func[testcase[index].split(\"/\")[0]].keys():\n",
    "                        dict_testcase2func[testcase[index].split(\"/\")[0]][func].append(\"FP\")\n",
    "                    else:\n",
    "                        dict_testcase2func[testcase[index].split(\"/\")[0]][func] = [\"FP\"]\n",
    "                with open(\"BGRU/result_analyze_0.4_k1/FP/\"+str(index)+\".pkl\",\"wb\") as f:\n",
    "                    pickle.dump(list([layer_output[0][j]]),f)###############################################\n",
    "                with open(\"BGRU/result_analyze_0.4_k1/FP_testcase_id_0514.txt\",'a+') as ffp:\n",
    "                    ffp.write(testcase[index]+'\\n')\t\t\t\t\t\n",
    "                    \n",
    "            if y_pred == 1 and labels[index] == 1:\n",
    "                TP += 1\n",
    "                TP_index.append(index)\n",
    "                flag_l = False\n",
    "            #基于切片中的漏洞行位置判断是否正确\n",
    "                for pred in result:\n",
    "                    if linetokens[index][pred] in vpointers[index]:\n",
    "                        flag_l = True\n",
    "                        break\n",
    "                if flag_l:\n",
    "                    TP_l += 1\n",
    "                else:\n",
    "                    FN_l += 1\n",
    "                if not testcase[index].split(\"/\")[0] in dict_testcase2func.keys():\n",
    "                    dict_testcase2func[testcase[index].split(\"/\")[0]]={}\n",
    "                for func in funcs[index]:\n",
    "                    if func in dict_testcase2func[testcase[index].split(\"/\")[0]].keys():\n",
    "                        dict_testcase2func[testcase[index].split(\"/\")[0]][func].append(\"TP\")\n",
    "                    else:\n",
    "                        dict_testcase2func[testcase[index].split(\"/\")[0]][func] = [\"TP\"]\n",
    "                with open(\"BGRU/result_analyze_0.4_k1/TP/\"+str(index)+\".pkl\",\"wb\") as f:\n",
    "                    pickle.dump(list([layer_output[0][j]]),f)###########################################\n",
    "                with open(\"BGRU/result_analyze_0.4_k1/TP_testcase_id_0514.txt\",'a+') as ftp:\n",
    "                    ftp.write(testcase[index]+'\\n')\n",
    "         \n",
    "            results[testcase[index]] = result\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "        \n",
    "        #保存预测的漏洞行行号\n",
    "    with open(resultPath+\"_result.pkl\", 'wb') as f:#############################3###########3\n",
    "        pickle.dump(results, f)\n",
    "        \n",
    "        #保存testcase到函数的预测映射\n",
    "    with open(resultPath+\"_dict_testcase2func.pkl\", 'wb') as f:#############################\n",
    "        pickle.dump(dict_testcase2func, f)\n",
    "        \n",
    "        #保存TP的结果\n",
    "    with open(\"TP_index_0.4_k2_BGRU.pkl\", 'wb') as f:\n",
    "        pickle.dump(TP_index, f)\n",
    "        \n",
    "        #记录实验结果\n",
    "    with open(resultPath, 'a') as fwrite:#######################################\n",
    "            #实验基本信息\n",
    "        fwrite.write('test_samples_num: '+ str(len(dataset)) + '\\n')\n",
    "        fwrite.write('train_dataset: ' + str(traindataSet_path) + '\\n')#######################\n",
    "        fwrite.write('test_dataset: ' + str(filename) + '\\n')\n",
    "        fwrite.write('model: ' + weightPath + '\\n')\n",
    "        #漏洞分类指标\n",
    "        fwrite.write('TP:' + str(TP) + ' FP:' + str(FP) + ' FN:' + str(FN) + ' TN:' + str(TN) + '\\n')\n",
    "        print('TP:' ,TP , ' FP:' ,FP , ' FN:',FN , ' TN:' ,TN )\n",
    "        FPR = FP / (FP + TN)\n",
    "        fwrite.write('FPR: ' + str(FPR) + '\\n')\n",
    "        FNR = FN / (TP + FN)\n",
    "        fwrite.write('FNR: ' + str(FNR) + '\\n')\n",
    "        accuracy = (TP + TN) / (len(dataset))\n",
    "        fwrite.write('accuracy: ' + str(accuracy) + '\\n')\n",
    "        precision = TP / (TP + FP)\n",
    "        fwrite.write('precision: ' + str(precision) + '\\n')\n",
    "        recall = TP / (TP + FN)\n",
    "        fwrite.write('recall: ' + str(recall) + '\\n')\n",
    "        f_score = (2 * precision * recall) / (precision + recall)\n",
    "        fwrite.write('fbeta_score: ' + str(f_score) + '\\n')\n",
    "        #漏洞定位指标\n",
    "        fwrite.write('TP_l:' + str(TP_l) + ' FP_l:' + str(FP_l) + ' FN_l:' + str(FN_l) + ' TN:' + str(TN_l) + '\\n')\n",
    "        FPR_l = FP_l / (FP_l + TN_l)\n",
    "        fwrite.write('FPR_location: ' + str(FPR_l) + '\\n')\n",
    "        FNR_l = FN_l / (TP_l + FN_l)\n",
    "        fwrite.write('FNR_location: ' + str(FNR_l) + '\\n')\n",
    "        accuracy_l = (TP_l + TN_l) / (TP_l + FP_l + FN_l + TN_l)\n",
    "        fwrite.write('accuracy_location: ' + str(accuracy_l) + '\\n')\n",
    "        precision_l = TP_l / (TP_l + FP_l)\n",
    "        fwrite.write('precision_location: ' + str(precision_l) + '\\n')\n",
    "        recall_l = TP_l / (TP_l + FN_l)\n",
    "        fwrite.write('recall_location: ' + str(recall_l) + '\\n')\n",
    "        f_score_l = (2 * precision_l * recall_l) / (precision_l + recall_l)\n",
    "        fwrite.write('fbeta_score_location: ' + str(f_score_l) + '\\n')\n",
    "        fwrite.write('--------------------\\n')\n",
    "        \n",
    "    print(\"\\nf1: \",f_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "113f541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote model\n",
      "Train...\n",
      "64\n",
      "================================================================================2021-07-20 17:05:12\n",
      "64\n",
      "batch [1/9], Loss: 0.6463\n",
      "64\n",
      "batch [2/9], Loss: 0.9428\n",
      "64\n",
      "batch [3/9], Loss: 0.6221\n",
      "64\n",
      "batch [4/9], Loss: 0.6764\n",
      "64\n",
      "batch [5/9], Loss: 0.6666\n",
      "64\n",
      "batch [6/9], Loss: 0.6586\n",
      "64\n",
      "batch [7/9], Loss: 0.6475\n",
      "64\n",
      "batch [8/9], Loss: 0.6349\n",
      "64\n",
      "batch [9/9], Loss: 0.6324\n",
      "64\n",
      "batch [10/9], Loss: 0.6378\n",
      "Epoch [1], Loss: 0.6765\n",
      "================================================================================2021-07-20 17:06:14\n",
      "64\n",
      "batch [1/9], Loss: 0.6107\n",
      "64\n",
      "batch [2/9], Loss: 0.6089\n",
      "64\n",
      "batch [3/9], Loss: 0.6115\n",
      "64\n",
      "batch [4/9], Loss: 0.6111\n",
      "64\n",
      "batch [5/9], Loss: 0.6090\n",
      "64\n",
      "batch [6/9], Loss: 0.5985\n",
      "64\n",
      "batch [7/9], Loss: 0.5954\n",
      "64\n",
      "batch [8/9], Loss: 0.5947\n",
      "64\n",
      "batch [9/9], Loss: 0.5866\n",
      "64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-1bd6d1ae2ff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#model = local_model.send(duet)#send the model to our partners Duet Server.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweightPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"加载模型\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-f240ad48aaaa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(remote_torch, model, weightPath)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"To evaluate training progress\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mrequest_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mtimeout_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             )\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m#print(local_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/core/pointer/pointer.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, request_block, timeout_secs, reason, delete_obj, verbose)\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mtimeout_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             )\n\u001b[1;32m    277\u001b[0m             if (\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/core/pointer/pointer.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, reason, block, timeout_secs, verbose)\u001b[0m\n\u001b[1;32m    472\u001b[0m                         )\n\u001b[1;32m    473\u001b[0m                         response = self.client.send_immediate_msg_with_reply(\n\u001b[0;32m--> 474\u001b[0;31m                             \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus_msg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                         )\n\u001b[1;32m    476\u001b[0m                         \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/core/node/common/client.py\u001b[0m in \u001b[0;36msend_immediate_msg_with_reply\u001b[0;34m(self, msg, route_index)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigning_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigning_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroutes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroute_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_immediate_msg_with_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;31m# check if we have an ExceptionMessage to trigger a local exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/core/io/route.py\u001b[0m in \u001b[0;36msend_immediate_msg_with_reply\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSignedImmediateSyftMessageWithReply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     ) -> SignedImmediateSyftMessageWithoutReply:\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_immediate_msg_with_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_object2proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSoloRoute_PB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/connections/webrtc.py\u001b[0m in \u001b[0;36msend_immediate_msg_with_reply\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;31m# properly fix this!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             return validate_type(\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_sync_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(future, debug)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_when\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86400\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscheduled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             else None)\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mevent_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#PART 3: Training\n",
    "if __name__ == '__main__':\n",
    "    testdataSet_path = \"./data/dl_input/nvd/test\"  #测试集路径\n",
    "  #  realtestdataSetPath = \"../data_preprocess/data/realdata/aftercut/\"  \n",
    "    weightPath = './model/bgru_0.4_k=1_0514.pt'  #保存模型的路径\n",
    "    resultPath = \"./BGRU/result/bgru_pysyft_com_0.4_k=1_0514.2\"  #测试结果保存路径\n",
    "\n",
    "    #model = local_model.send(duet)#send the model to our partners Duet Server. \n",
    "\n",
    "    train(remote_torch,model,weightPath)\n",
    "    print(\"加载模型\")\n",
    "    if not model.is_local:\n",
    "        local_model = model.get(request_block=True,name=\"model_download\",reason=\"test evaluation\",timeout_secs=5)\n",
    "    else:\n",
    "        local_model = model\n",
    "    print(\"加载模型完成\") \n",
    "    test(local_model,torch,batch_size, maxlen, vector_dim,weightPath,testdataSet_path,resultPath)\n",
    "        \n",
    "    print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
